{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanahdia/scrapy-clustering/blob/main/HW3_clustering_sana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDceMCFtGDsp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import nltk\n",
        "from io import StringIO\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json('dataa.json', orient='records')"
      ],
      "metadata": {
        "id": "EFTtO1w2QdRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = (df['title'].fillna('') + ' ' + df['description'].fillna(''))\n",
        "x = x.str.replace(r'[\\t\\n\\r]', '').str.replace('\\s+', ' ')\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW0cGtSaQnsL",
        "outputId": "4dac4a2d-f5a5-4eb0-e10a-f5acbdfaa95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      Having previously vowed to pardon Jan. 6 riot...\n",
            "1                                                      \n",
            "2      On March 19, 1995, after a 21-month hiatus, M...\n",
            "3      Having previously vowed to pardon Jan. 6 riot...\n",
            "4      Last year, a team from New Jersey called Fair...\n",
            "5      Paid loyalty programs are all the rage in the...\n",
            "6     Social media influencer is charged with joinin...\n",
            "7     Tuesday’s primaries include a key Senate race ...\n",
            "8     Pro-Trump Michigan attorney arrested after hea...\n",
            "9     Trump’s lawyers say it is impossible for him t...\n",
            "10    Timelapse reveals Notre Dame’s new spire, rebu...\n",
            "11    Woman wails over husband’s body following Isra...\n",
            "12    Attempt to repeal ban on female genital mutila...\n",
            "13    Tuesday’s primaries include a key Senate race ...\n",
            "14    High-profile elections in Ohio could give Repu...\n",
            "15    Trump backs Kevin McCarthy protege in Californ...\n",
            "16    Bettors counting on upsets as they put money o...\n",
            "17    March Madness brackets are here. Here’s how to...\n",
            "18    The Hur interview transcript offers a window i...\n",
            "19    A new kind of hospital is coming to rural Amer...\n",
            "20    Former Mormon bishop highlighted in AP investi...\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-99b83178118b>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  x = x.str.replace(r'[\\t\\n\\r]', '').str.replace('\\s+', ' ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, min_df=5)\n",
        "df['title'].fillna('', inplace=True)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['title'])\n",
        "terms = tfidf_vectorizer.get_feature_names_out()\n",
        "print(\"List of terms included in the TF-IDF matrix:\")\n",
        "print(terms)\n",
        "print(\"Size of the TF-IDF matrix:\", tfidf_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUh6XwQPRxB1",
        "outputId": "c0420f12-1ba9-4d50-c9ea-25a51c197c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of terms included in the TF-IDF matrix:\n",
            "['for' 'in' 'to' 'trump']\n",
            "Size of the TF-IDF matrix: (21, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "kmeans = KMeans(init='k-means++')\n",
        "kmeans.fit(tfidf_matrix)\n",
        "cluster_counts = pd.Series(kmeans.labels_).value_counts().sort_index()\n",
        "print(\"Number of elements in each cluster:\")\n",
        "print(cluster_counts)\n",
        "print(\"Content of the clusters:\")\n",
        "for i, cluster_center in enumerate(kmeans.cluster_centers_):\n",
        "    print(\"Cluster\", i)\n",
        "    cluster_indices = kmeans.labels_ == i\n",
        "    cluster_samples = df[cluster_indices].head()\n",
        "    print(cluster_samples)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TT_08ZuSZSF",
        "outputId": "f01845b4-2930-4a78-f43e-b432f9270acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of elements in each cluster:\n",
            "0    10\n",
            "1     1\n",
            "2     3\n",
            "3     2\n",
            "4     1\n",
            "5     1\n",
            "6     2\n",
            "7     1\n",
            "dtype: int64\n",
            "Content of the clusters:\n",
            "Cluster 0\n",
            "  title                                        description\n",
            "0        Having previously vowed to pardon Jan. 6 riote...\n",
            "1                                                         \n",
            "2        On March 19, 1995, after a 21-month hiatus, Mi...\n",
            "3        Having previously vowed to pardon Jan. 6 riote...\n",
            "4        Last year, a team from New Jersey called Fairl...\n",
            "\n",
            "Cluster 1\n",
            "                                                title description\n",
            "14  High-profile elections in Ohio could give Repu...            \n",
            "\n",
            "Cluster 2\n",
            "                                                title description\n",
            "7   Tuesday’s primaries include a key Senate race ...            \n",
            "13  Tuesday’s primaries include a key Senate race ...            \n",
            "15  Trump backs Kevin McCarthy protege in Californ...            \n",
            "\n",
            "Cluster 3\n",
            "                                                title description\n",
            "17  March Madness brackets are here. Here’s how to...            \n",
            "19  A new kind of hospital is coming to rural Amer...            \n",
            "\n",
            "Cluster 4\n",
            "                                               title description\n",
            "9  Trump’s lawyers say it is impossible for him t...            \n",
            "\n",
            "Cluster 5\n",
            "                                                title description\n",
            "12  Attempt to repeal ban on female genital mutila...            \n",
            "\n",
            "Cluster 6\n",
            "                                                title description\n",
            "11  Woman wails over husband’s body following Isra...            \n",
            "20  Former Mormon bishop highlighted in AP investi...            \n",
            "\n",
            "Cluster 7\n",
            "                                               title description\n",
            "8  Pro-Trump Michigan attorney arrested after hea...            \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=5, init='k-means++')"
      ],
      "metadata": {
        "id": "qIWXunJhScTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.fit(tfidf_matrix)\n",
        "cluster_counts = pd.Series(kmeans.labels_).value_counts().sort_index()\n",
        "print(\"Number of elements in each cluster:\")\n",
        "print(cluster_counts)\n",
        "print(\"Content of the clusters:\")\n",
        "for i, cluster_center in enumerate(kmeans.cluster_centers_):\n",
        "    print(\"Cluster\", i)\n",
        "    cluster_indices = kmeans.labels_ == i\n",
        "    cluster_samples = df[cluster_indices].head()\n",
        "    print(cluster_samples)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75qMEa1kShtj",
        "outputId": "1558d734-2381-4ed4-8265-ca184503c6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of elements in each cluster:\n",
            "0     2\n",
            "1    10\n",
            "2     3\n",
            "3     4\n",
            "4     2\n",
            "dtype: int64\n",
            "Content of the clusters:\n",
            "Cluster 0\n",
            "                                                title description\n",
            "9   Trump’s lawyers say it is impossible for him t...            \n",
            "12  Attempt to repeal ban on female genital mutila...            \n",
            "\n",
            "Cluster 1\n",
            "  title                                        description\n",
            "0        Having previously vowed to pardon Jan. 6 riote...\n",
            "1                                                         \n",
            "2        On March 19, 1995, after a 21-month hiatus, Mi...\n",
            "3        Having previously vowed to pardon Jan. 6 riote...\n",
            "4        Last year, a team from New Jersey called Fairl...\n",
            "\n",
            "Cluster 2\n",
            "                                                title description\n",
            "11  Woman wails over husband’s body following Isra...            \n",
            "14  High-profile elections in Ohio could give Repu...            \n",
            "20  Former Mormon bishop highlighted in AP investi...            \n",
            "\n",
            "Cluster 3\n",
            "                                                title description\n",
            "7   Tuesday’s primaries include a key Senate race ...            \n",
            "8   Pro-Trump Michigan attorney arrested after hea...            \n",
            "13  Tuesday’s primaries include a key Senate race ...            \n",
            "15  Trump backs Kevin McCarthy protege in Californ...            \n",
            "\n",
            "Cluster 4\n",
            "                                                title description\n",
            "17  March Madness brackets are here. Here’s how to...            \n",
            "19  A new kind of hospital is coming to rural Amer...            \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "ovEQyWOESnEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "french_stopwords = set(stopwords.words('french'))\n",
        "french_stemmer = SnowballStemmer('french')\n",
        "def process_text(text):\n",
        "    words = word_tokenize(text)\n",
        "    filtered_stemmed = [french_stemmer.stem(word) for word in words if word.lower() not in french_stopwords]\n",
        "    return ' '.join(filtered_stemmed)\n",
        "df = pd.read_json('dataa.json', orient='records')\n",
        "df = df.dropna()\n",
        "df['processed_text'] = df['description'].apply(process_text)\n",
        "if df['processed_text'].empty:\n",
        "    print(\"No meaningful text found after preprocessing.\")\n",
        "else:\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), analyzer='word')\n",
        "    X = vectorizer.fit_transform(df['processed_text'])\n",
        "    if X.shape[0] >= 10:\n",
        "        kmeans = KMeans(n_clusters=10).fit(X)\n",
        "        df['cluster'] = kmeans.labels_\n",
        "        print(df.head())\n",
        "    else:\n",
        "        print(\"Number of samples is less than the number of clusters. Please reduce the number of clusters.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEDmofS0SsWC",
        "outputId": "e5249dfb-efad-4eee-f1d9-da4f569e55f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No meaningful text found after preprocessing.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Package omw is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    }
  ]
}